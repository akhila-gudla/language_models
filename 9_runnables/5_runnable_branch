from langchain_perplexity import ChatPerplexity
from dotenv import load_dotenv
from langchain_core.prompts import PromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain.schema.runnable import RunnableBranch,RunnablePassthrough,RunnableSequence,RunnableParallel
from langchain_core.runnables import Condition

# example : if the output of one runnable is too long then pass it to another runnable for summarization else just pass it as it is
load_dotenv()
model = ChatPerplexity(model="sonar")
string_parser = StrOutputParser()

prompt1 = PromptTemplate(
    template="Write a detailed report on {topic}",
    input_variables=["topic"],
)
prompt2 = PromptTemplate(
    template="Summarise the text {text} in less than 500 words",
    input_variables=["text"],
)
detailed_report_chain = RunnableSequence(prompt1, model, string_parser)
branch_chain = RunnableBranch(
    Condition(lambda x: len(x.split()) > 500, RunnableSequence(prompt2, model, string_parser)),
    RunnablePassthrough(),
)
final_chain =RunnableSequence(detailed_report_chain, branch_chain)
result =final_chain.invoke({"topic": "Artificial Intelligence"})
print(result)